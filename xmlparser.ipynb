{"cells": [{"cell_type": "markdown", "id": "de205ebb-3cfd-45d1-8050-9e49e90f0aff", "metadata": {}, "source": "# Installing Dependencies"}, {"cell_type": "code", "execution_count": 34, "id": "44543182-155b-44bb-a607-e8c5a8f4f52c", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "Marking com.databricks:spark-xml_2.12:0.16.0 for download\nObtained 2 files\n"}, {"data": {"text/plain": "error: error while loading DefaultSource, class file '/tmp/toree-tmp-dir14656234910998677901/toree_add_deps/https/repo1.maven.org/maven2/com/databricks/spark-xml_2.12/0.16.0/spark-xml_2.12-0.16.0.jar(com/databricks/spark/xml/DefaultSource.class)' has location not matching its contents: contains class DefaultSource\nerror: error while loading XmlDataToCatalyst, class file '/tmp/toree-tmp-dir14656234910998677901/toree_add_deps/https/repo1.maven.org/maven2/com/databricks/spark-xml_2.12/0.16.0/spark-xml_2.12-0.16.0.jar(com/databricks/spark/xml/XmlDataToCatalyst.class)' has location not matching its contents: contains class XmlDataToCatalyst\nerror: error while loading XmlInputFormat, class file '/tmp/toree-tmp-dir14656234910998677901/toree_add_deps/https/repo1.maven.org/maven2/com/databricks/spark-xml_2.12/0.16.0/spark-xml_2.12-0.16.0.jar(com/databricks/spark/xml/XmlInputFormat.class)' has location not matching its contents: contains class XmlInputFormat\nerror: error while loading XmlOptions, class file '/tmp/toree-tmp-dir14656234910998677901/toree_add_deps/https/repo1.maven.org/maven2/com/databricks/spark-xml_2.12/0.16.0/spark-xml_2.12-0.16.0.jar(com/databricks/spark/xml/XmlOptions.class)' has location not matching its contents: contains class XmlOptions\nerror: error while loading XmlReader, class file '/tmp/toree-tmp-dir14656234910998677901/toree_add_deps/https/repo1.maven.org/maven2/com/databricks/spark-xml_2.12/0.16.0/spark-xml_2.12-0.16.0.jar(com/databricks/spark/xml/XmlReader.class)' has location not matching its contents: contains class XmlReader\nerror: error while loading XmlRecordReader, class file '/tmp/toree-tmp-dir14656234910998677901/toree_add_deps/https/repo1.maven.org/maven2/com/databricks/spark-xml_2.12/0.16.0/spark-xml_2.12-0.16.0.jar(com/databricks/spark/xml/XmlRecordReader.class)' has location not matching its contents: contains class XmlRecordReader\nerror: error while loading XmlRelation, class file '/tmp/toree-tmp-dir14656234910998677901/toree_add_deps/https/repo1.maven.org/maven2/com/databricks/spark-xml_2.12/0.16.0/spark-xml_2.12-0.16.0.jar(com/databricks/spark/xml/XmlRelation.class)' has location not matching its contents: contains class XmlRelation\n"}, "metadata": {}, "output_type": "display_data", "source": "user"}, {"name": "stdout", "output_type": "stream", "text": "Marking com.databricks:spark-xml_2.12:0.16.0 for download\nObtained 2 files\n"}], "source": "%AddDeps com.databricks spark-xml_2.12 0.16.0"}, {"cell_type": "markdown", "id": "21766dcf-491e-4176-8e97-7e1f22f281bd", "metadata": {}, "source": "# Parses XML file and Writes Parquet Output"}, {"cell_type": "code", "execution_count": 35, "id": "b692873b-ee21-4ded-b73e-c297b7343e96", "metadata": {}, "outputs": [], "source": "import org.apache.spark.sql.SparkSession\nimport com.databricks.spark.xml._\nimport org.apache.spark.sql._\nimport org.apache.spark.sql.functions.col\nimport org.apache.spark.sql.functions._\nimport scala.io.Source \nimport org.apache.spark.sql.types.{DataType, StructType}"}, {"cell_type": "markdown", "id": "a05288a4-8bc5-4a67-afaa-e60cd511acd2", "metadata": {}, "source": "## Reads Input and Output"}, {"cell_type": "code", "execution_count": 36, "id": "434f8b0b-b740-4dca-af34-738459a0b3e8", "metadata": {}, "outputs": [{"data": {"text/plain": "inputPath = gs://dataproc-cookbook/chapter2/spark/scala/inputfiles/menu.xml\noutputPath = gs://dataproc-cookbook/chapter2/spark/scala/outputfiles/\n"}, "metadata": {}, "output_type": "display_data", "source": "user"}, {"data": {"text/plain": "gs://dataproc-cookbook/chapter2/spark/scala/outputfiles/"}, "execution_count": 36, "metadata": {}, "output_type": "execute_result"}], "source": "//val inputPath = args(0)\nval inputPath = \"gs://dataproc-cookbook/chapter2/spark/scala/inputfiles/menu.xml\"\nval outputPath = \"gs://dataproc-cookbook/chapter2/spark/scala/outputfiles/\""}, {"cell_type": "code", "execution_count": 37, "id": "7dc4ee69-faf7-4bc6-bfdc-5abf9c280c99", "metadata": {}, "outputs": [{"data": {"text/plain": "rowTag = food\n"}, "metadata": {}, "output_type": "display_data", "source": "user"}, {"data": {"text/plain": "food"}, "execution_count": 37, "metadata": {}, "output_type": "execute_result"}], "source": "val rowTag = \"food\""}, {"cell_type": "markdown", "id": "02450645-0327-4017-87df-97e2b76a38ae", "metadata": {}, "source": "## Infers Schema"}, {"cell_type": "code", "execution_count": 38, "id": "19c4ab14-c113-406d-b848-ae6c08350243", "metadata": {}, "outputs": [{"data": {"text/plain": "inputDf = [calories: bigint, description: string ... 2 more fields]\n"}, "metadata": {}, "output_type": "display_data", "source": "user"}, {"data": {"text/plain": "[calories: bigint, description: string ... 2 more fields]"}, "execution_count": 38, "metadata": {}, "output_type": "execute_result"}], "source": "var inputDf = spark.read.option(\"rowTag\", rowTag).xml(inputPath)"}, {"cell_type": "code", "execution_count": 39, "id": "21211886-f075-4343-8077-e1ce802b2f55", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "+--------+--------------------+--------------------+-----+\n|calories|         description|                name|price|\n+--------+--------------------+--------------------+-----+\n|     650|Two of our famous...|     Belgian Waffles|$5.95|\n|     900|Light Belgian waf...|Strawberry Belgia...|$7.95|\n|     900|Light Belgian waf...|Berry-Berry Belgi...|$8.95|\n|     600|Thick slices made...|        French Toast|$4.50|\n|     950|Two eggs, bacon o...| Homestyle Breakfast|$6.95|\n+--------+--------------------+--------------------+-----+\n\n"}], "source": "inputDf.show()"}, {"cell_type": "markdown", "id": "f86ce168-8cbd-42e0-8a15-0878210ed81a", "metadata": {}, "source": "## Writes the Parquet output to GCS"}, {"cell_type": "code", "execution_count": 40, "id": "1bb6c18b-e408-4e03-80b8-091987ddf157", "metadata": {}, "outputs": [], "source": "inputDf.write.mode(SaveMode.Overwrite).parquet(outputPath)"}], "metadata": {"kernelspec": {"display_name": "Apache Toree - Scala", "language": "scala", "name": "apache_toree_scala"}, "language_info": {"codemirror_mode": "text/x-scala", "file_extension": ".scala", "mimetype": "text/x-scala", "name": "scala", "pygments_lexer": "scala", "version": "2.12.15"}}, "nbformat": 4, "nbformat_minor": 5}